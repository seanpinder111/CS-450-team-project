Introduction:
https://www.basketball-reference.com
Some members of our team are avid NBA fans. We thought it
would be interesting to use the wealth of available basketball
statistics to predict something about player or team performance.

We considered several ideas including:
* Prediction of individual performance for second year players
* Prediction of NBA champions
* Prediction of MVP for each year

Finally we determined that we would try predicting the world champions
given a team's stats for the season. Beyond just predicting whether or not
a given team would win the title, we wanted to predict how far they would
advance in the playoffs in a given year using a numeric ranking from 0-5,
0 being a lottery year and 5 being the championship.

This problem was interesting to us because with the playoffs coming up,
we can use this year's data to predict the results with reasonable accuracy.
More importantly, we hoped that we could find a way to isolate key statistics
that lead to playoff success in NBA teams.

We eventually found....... To Be Continued

Data Preparation:
(Brigham)


Mining / Learning from the data:

We tried a number of different algorithms with the aim of choosing one or two different models with a high enough accuracy to be respectable. Among the algorithms we tried were a neural network, naive bayes, K-nearest neighbors, support vector machine, decision tree, and multi-layer perceptron regression. Ultimately the one that performed the best was our decision tree; the other advantage of using a decision tree being that we were able to visualize our model in a way that might be more difficult with other algorithms.


Results:
(NOT TILL LATER)


Conclusions:
(NOT TILL LATER)



Lessons Learned:
We learned quite a few lessons regarding machine learning algorithms, types of data (and their uses), and learning strategies.
As mentioned above, we trained quite a few different algorithms in order to find the best fit for our application. We learned that this is actually a good strategy to finding the best algorithm for a given data set. Through our experimentations we found the best fit for our data.
	Next we learned how different types of data yield different results. We trained and tested on raw numeric, normalized, and we even tried binned data for learning. This helped concretize our textbook knowledge with real life applications. Each type of data mentioned has their own use but we found that normalized data worked the best for our learning purposes.
	Finally we picked up some new strategies when it comes to machine learning. Collaboration is first and foremost on this list. As a group we were able to pool our knowledge to accomplish our task. Another strategy we found worked well has to do with the type of problem we were facing. It was important for us not to set unrealistic expectations for our predictions. As with any sport prediction there is no perfect recipe for winning. We definitely couldnâ€™t expect that our predictions were going to get high accuracy scores, it all depends on the kind of prediction at hand.
